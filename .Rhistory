}
# Create an empty vector to store the output
temp <- NULL
for(i in 1:nrow(table)){
temp <- c(temp, hamming(og1[which(og1$C == table$Cx[i]),-1],
og1[which(og1$C == table$Cy[i]),-1]))
}
# Add Hamming distance to table
table$Hamming <- temp
# Arrange the table
table %>%
# Add a column indicating whether characters are both consonants or vowels
mutate(Type = case_when(Consonant.x == 1 & Consonant.y == 1 & Vowel.x == 1 & Vowel.y == 1 ~ "both.CV",
Consonant.x == 1 & Consonant.y == 1 ~ "both.C",
Vowel.x == 1 & Vowel.y == 1 ~ "both.V",
TRUE ~ "different")) %>%
select(Cx, Cy, Hamming, Type, everything()) -> table
# Sanity check
table
# Plot the distributions of Hamming distance across Cs and Vs
table %>%
mutate(Hamming = as.numeric(Hamming)) %>%
ggplot(aes(x = Type, y = Hamming)) +
geom_violin(color = "blue", fill = "gold") +
# add boxplot
geom_boxplot(width = 0.3,
color = "blue", fill = "gold") +
# with mean +/- 2 standard deviations
stat_summary(fun.data=mean_sdl,
geom="pointrange", color="blue") +
# add points
geom_point(aes(color=Type), position=position_jitterdodge())
# Reformat the table to rename columns and pare out extraneous columns (at the moment, the table is set for analysis of consonants/vowels across different scripts)
reformatted <- table
# Renames the column names for model building
colnames(reformatted)[1] <- "CHARACTER1"
colnames(reformatted)[2] <- "CHARACTER2"
colnames(reformatted)[3] <- "DISTANCE"
colnames(reformatted)[7] <-"SCRIPT"
colnames(reformatted)[4] <-"IDENTICAL"
colnames(reformatted)[5] <-"CONSONANT"
reformatted[10] <- NULL
reformatted[9] <- NULL
reformatted[8] <- NULL
# Add additional code to pare out any letters that have been double-coded. #HELP
reformatted[reformatted$CONSONANT == 1 & reformatted$Vowel.x == 1, ]
# Build the null model
null <- lmer(DISTANCE ~ (1|CHARACTER1) + (1|CHARACTER2) + (1|SCRIPT), reformatted) #HELP
summary(null)
# Build test model
test <- lmer(DISTANCE ~ IDENTICAL + (1|CHARACTER1) + (1|CHARACTER2) + (1|SCRIPT), reformatted) #HELP
summary(null)
# Compare the two models
anova(null,test)
### 7. Simulate completely random scripts and scripts with conditional dependencies. ###
# Create the necessary functions
# Return the Hamming distance between two strings
hamming = function(str1,str2) {
bool <- str1==str2
return(length(bool[bool==FALSE]))
}
shuffle.rules <- function(data,Nsets) {
Ncharacters <- nrow(data)
Nrules <- ncol(data)
permutations <- array(1:(Ncharacters*Nrules*Nsets),dim=c(Ncharacters,Nrules,Nsets))
rule.ordering <- matrix(1:(Nrules*Nsets),nrow=Nsets,ncol=Nrules)
for(i in 1:Nsets) {
repeat {
rule.ordering[i,] <- sample(ncol(data))
permutations[,,i] <- data[,rule.ordering[i,]]
if(length(duplicated(rule.ordering)[duplicated(rule.ordering)==TRUE])==0){
break
}
}
}
return(permutations)
}
# Compute the conditional probability of a rule following another rule
conditional.prob <- function(data) {
Nrules <- ncol(data)
prob <- matrix(0:0,ncol=Nrules,nrow=2)+0.5
for(i in 2:Nrules) {
prev.rule <- data[,i-1]
current.rule <- data[,i]
N0 <- current.rule[prev.rule==0]
prob[1,i] <- sum(N0)/length(N0)
N1 <- current.rule[prev.rule==1]
prob[2,i] <- sum(N1)/length(N1)
}
return(prob)
}
# Generate a set of random characters. This is a function with two arguments: (1) Ncharacters is number of desired characters, (2) Nrules is number of desired rules
gen.set <- function(Ncharacters, Nrules){
#create matrix of arbitrary numeric labels to populate with a loop
characters <- matrix(1:(Nrules*Ncharacters), ncol = Nrules, nrow = Ncharacters)
#run loop to populate matrix
for(i in 1:Ncharacters){
#replace empty row with random set of 0s and 1s
characters[i, ] <- sample(c(0,1), Nrules, replace = TRUE)
#if random set of 0s and 1s matches a previous set, regenerate it until it no longer matches any previous sets
while(length(duplicated(characters)[duplicated(characters) == TRUE]) > 0 || identical(characters[i, ], replicate(Nrules, 0))){
characters[i, ] <- sample(c(0, 1), Nrules, replace = TRUE)
}
}
#return as a matrix
#return(as.data.frame(characters)) #option for outputting as data frame instead of matrix if you choose
return(characters)
}
#example of running gen.set in an lapply loop, so the output is a list of matrices
random_example <- lapply(1:100, function(x){gen.set(60, 23)})
#if you want to convert this list of matrices into an array instead, run the following
random_example_array <- array(unlist(random_example), dim = c(nrow(random_example[[1]]), ncol(random_example[[1]]), length(random_example)))
#generate a set of random characters that keeps the interactions between rules of a given data set
gen.set.inter <- function(data, Ncharacters) {
#use the number of columns in the real data to set the number of rules for the simulated data
Nrules <- ncol(data)
#compute the conditional probabilities
p1 <- conditional.prob(data)
p0 <- 1-p1
#create matrix of arbitrary numeric labels to populate with a loop
characters <- matrix(1:(Nrules*Ncharacters), ncol = Nrules, nrow = Ncharacters)
#mason: "not commenting here, but it looks right to me"
for(i in 1:Ncharacters) {
repeat {
for(j in 1:Nrules) {
if(j != 1) {
if(characters[i, j-1] == 1) {
characters[i,j] <- sample(0:1, size = 1, replace = TRUE, prob = c(p0[2, j], p1[2, j]))
}
else {
characters[i,j] <- sample(0:1, size = 1, replace = TRUE, prob = c(p0[1, j], p1[1, j]))
}
}
else {
characters[i, j] <- sample(0:1, size = 1, replace = TRUE, prob = c(p0[2, j], p1[2, j]))
}
}
if(length(duplicated(characters)[duplicated(characters) == TRUE]) == 0 && identical(characters[i, ], replicate(Nrules, 0)) == FALSE){
break
}
}
}
#return as a matrix
return(characters)
}
#example of running gen.set.inter in an lapply loop, so the output is a list of matrices
random_example <- lapply(1:100, function(x){gen.set.inter(data, 60)})
# Return the Hamming distance of all the letters in a script as a matrix
distance <- function(characters) {
Ncharacters <- nrow(characters)
dist <- matrix(0:0, Ncharacters,Ncharacters)
for(i in 1:Ncharacters) {
for(j in 1:Ncharacters) {
dist[i,j] <- hamming(characters[i,],characters[j,])
}
}
return(dist)
}
# Average Hamming distance of a set of characters
avrdist <- function(characters) {
dist <- distance(characters)
Ncharacters <- nrow(dist)
dist <- dist + diag(NA,Ncharacters)
avrdist <- mean(dist,na.rm=TRUE)
return(avrdist)
}
# Plot the histogram of the minimal pairs in the simulated sets and in the data
comparison.minimal <- function(data,sets) {
Ncharacters <- nrow(data)
Nrules <- ncol(data)
Nsets <- dim(sets)[3]
dist.data <- distance(data)
minimal.data <- length(dist.data[dist.data==1])/2
minimal <- 1:Nsets
for(i in 1:Nsets) {
minimal[i] <- length(distance(sets[,,i])[distance(sets[,,i])==1])/2
}
minimal.df <- as.data.frame(minimal)
ggplot(minimal.df) +
geom_bar(aes(x=minimal)) +
geom_point(aes(x=minimal.data,y=0),color="red") +
coord_cartesian(xlim = c(0, max(minimal) + minimal.data + 20))
}
# Plot the histogram of the average Hamming distance of the sets and the data
comparison.hamming <- function(data,sets) {
Ncharacters <- nrow(data)
Nrules <- ncol(data)
Nsets <- dim(sets)[3]
dist.data <- distance(data)
avrdist.data <- avrdist(data)
avrdist.sets <- 1:Nsets
for(i in 1:Nsets) {
avrdist.sets[i] <- avrdist(sets[,,i])
}
avrdist.sets.df <- as.data.frame(avrdist.sets)
ggplot(avrdist.sets.df) + geom_histogram(aes(x=avrdist.sets),binwidth=0.03) + geom_point(aes(x=avrdist.data,y=0),color="red")
}
## Generating plots ##
## ---------------------------------------------------------------------------
#real_script <- as.matrix(data)
Nsets <- 100
Ncharacters <- nrow(data)
Nrules <- ncol(data)
#generate 100 random iterations of the two simulations
sets.random1 <- lapply(1:Nsets, function(x){gen.set(Ncharacters, Nrules)})
sets.inter1 <- lapply(1:Nsets, function(x){gen.set.inter(data, Ncharacters)})
sets.random1
sets.random1[1]
sets.random1[[1]]
sets.random1[[1]]
#### Run a decision tree on each simulation and then compare this output to that which is generated using real data ####
model <- rpart(character ~ ., # formula
method = "class",
data = sets.random1[[1]],
control = rpart.control(minsplit = 2,
minbucket = 1,
maxdepth = 30))
#### Run a decision tree on each simulation and then compare this output to that which is generated using real data ####
model <- rpart(character ~ ., # formula
method = "class",
data = as.data.frame(sets.random1[[1]]),
control = rpart.control(minsplit = 2,
minbucket = 1,
maxdepth = 30))
#### Run a decision tree on each simulation and then compare this output to that which is generated using real data ####
model <- rpart(character ~ ., # formula
method = "class",
data = sets.random1[[1]],
control = rpart.control(minsplit = 2,
minbucket = 1,
maxdepth = 30))
#now let's take one of the simulation outputs (i.e., the completley random one), and convert into a format friendly to the rpart code
test_data <- as.data.frame(sets.random1[[1]])
test_data <- cbind(character = as.factor(1:nrow(test_data)), test_data)
# Coerces to factors
test_data <- test_data %>% mutate_if(is.numeric,as.factor)
test_data
#now let's take one of the simulation outputs (i.e., the completley random one), and convert into a format friendly to the rpart code
test_data <- as.data.frame(sets.random1[[1]])
test_data <- cbind(character = as.factor(1:nrow(test_data)), test_data)
# Coerces to factors
test_data <- test_data %>% mutate_if(is.numeric,as.factor)
#### Run a decision tree on each simulation and then compare this output to that which is generated using real data ####
model <- rpart(character ~ ., # formula
method = "class",
data = test_data,
control = rpart.control(minsplit = 2,
minbucket = 1,
maxdepth = 30))
model
?rpart
#Then do this for each script in the set of dummy scripts created using the random method
#(*not* the conditional probabilites method)
informativeness <- function(p) {
-p*log(p) - (1-p)*log(1-p)
}
informativeness(0.1)
informativeness <- function(p) {
-p*log(p) - (1-p)*log(1-p)
}
for (i in 1:Nsets) {
test_data <- as.data.frame(sets.random1[[i]])
test_data <- cbind(character = as.factor(1:nrow(test_data)), test_data)
prop <- data.frame(colSums(test_data)/nrow(test_data))
inform <- data.frame(informativeness(prop))
rowMeans(inform)/nrow(test_data)
}
sets.random1[[1]]
i <- 1
test_data <- as.data.frame(sets.random1[[i]])
test_data <- cbind(character = as.factor(1:nrow(test_data)), test_data)
test_data
prop <- data.frame(colSums(test_data)/nrow(test_data))
temp <- as.data.frame(sets.random1[[i]])
colSums(sets.random1[[1]])
colSums(sets.random1[[1]])/nrow(sets.random1[[1]])
colSums(sets.random1[[i]])/nrow(sets.random1[[i]])
prop <- colSums(sets.random1[[i]])/nrow(sets.random1[[i]])
prop
informativeness(prop)
mean(informativeness(prop))
mean(informativeness(colSums(sets.random1[[i]])/nrow(sets.random1[[i]])))
sapply(1:Nsets, function(x){mean(informativeness(colSums(sets.random1[[x]])/nrow(sets.random1[[x]])))})
# Computing the distance between letters on all sets
dist.data <- distance(data)
dist.data
data
?distance
distance(data)
avrdist(data)
mean(dist.data)
avrdist.sets.random <= avrdist.data
avrdist.sets.random <- 1:Nsets
for(i in 1:Nsets) {
avrdist.sets.random[i] <- avrdist(sets.random1[,,i])
}
#simulated sets (random):
avrdist.sets.random <- 1:Nsets
avrdist.sets.random
#simulated sets (random):
avrdist.sets.random <- 1:Nsets
for(i in 1:Nsets) {
avrdist.sets.random[i] <- avrdist(sets.random1[,,i])
}
#simulated sets (random):
avrdist.sets.random <- 1:Nsets
for(i in 1:Nsets) {
avrdist.sets.random[i] <- avrdist(sets.random1[[i]])
}
avrdist.sets.random
#simulated sets (conditional provbabilities aka "CP"):
avrdist.sets.cp <- 1:Nsets
for(i in 1:Nsets) {
avrdist.sets.cp[i] <- avrdist(sets.inter1[[i]])
}
avrdist.sets.cp
#real set:
avrdist.data <- avrdist(data)
avrdist.sets.random <= avrdist.data
sum(avrdist.sets.random <= avrdist.data)/length(avrdist.sets.random)
palette(rainbow(6))
palette(rainbow(6))
rainbow(6)
randomcoloR::distinctColorPalette(20)
load("/Users/masonyoungblood/Downloads/names.RData")
names
load("/Users/masonyoungblood/Downloads/years.RData")
years
names
names[[1]]
names[[2]]
names[[3]]
names[[4]]
names[[5]]
years[[1]]
years[[2]]
years[[4]]
years[[5]]
load("/Users/masonyoungblood/Downloads/disrupt_model.RData")
disrupt_model[[1]]
disrupt_model[[2]]
setwd("~/Documents/Work/Fall 2022/Conservatism/ConservatismModel/code")
source("code/functions.R")
setwd("/Users/masonyoungblood/Documents/Work/Fall 2022/Conservatism/ConservatismModel")
source("code/functions.R")
#store required packages
pkgs <- unique(getParseData(parse("code/functions.R"))$text[getParseData(parse("code/functions.R"))$token == "SYMBOL_PACKAGE"])
#set parameters
n <- 10000
t <- 2000
t_2 <- 200
cost <- c(0.5, 0.5, 0.5, 0.5)
moves <- c(2, 2, 2, 2)
gamma <- c(0, 0.25, 0, 0.25)
f <- c(0, 2.5, 0, 2.5)
networked <- c(FALSE, FALSE, TRUE, TRUE)
props <- seq(0.1, 0.9, by = 0.1)
#put parameters into data frame
base_params <- data.frame(cost = cost, moves = moves, gamma = gamma, f = f, networked = networked)
disrupt_params <- data.frame(model = rep(1:length(cost), each = length(props)), props = rep(props, length(cost)), cost = rep(cost, each = length(props)), moves = rep(moves, each = length(props)), gamma = rep(gamma, each = length(props)), f = rep(f, each = length(props)), networked = rep(networked, each = length(props)))
#remove original parameter objects
rm(list = c("cost", "moves", "gamma", "f", "networked", "props"))
#set seed
set.seed(123)
base_model <- disrupt_model[[1]]
disrupt_model[[2]]
source("code/functions.R")
#store required packages
pkgs <- unique(getParseData(parse("code/functions.R"))$text[getParseData(parse("code/functions.R"))$token == "SYMBOL_PACKAGE"])
#set parameters
n <- 10000
t <- 2000
t_2 <- 200
cost <- c(0.5, 0.5, 0.5, 0.5)
moves <- c(2, 2, 2, 2)
gamma <- c(0, 0.25, 0, 0.25)
f <- c(0, 2.5, 0, 2.5)
networked <- c(FALSE, FALSE, TRUE, TRUE)
props <- seq(0.1, 0.9, by = 0.1)
#put parameters into data frame
base_params <- data.frame(cost = cost, moves = moves, gamma = gamma, f = f, networked = networked)
disrupt_params <- data.frame(model = rep(1:length(cost), each = length(props)), props = rep(props, length(cost)), cost = rep(cost, each = length(props)), moves = rep(moves, each = length(props)), gamma = rep(gamma, each = length(props)), f = rep(f, each = length(props)), networked = rep(networked, each = length(props)))
#remove original parameter objects
rm(list = c("cost", "moves", "gamma", "f", "networked", "props"))
#set seed
set.seed(123)
x <- 1
#store base model and compute status quo
base <- base_model[[disrupt_params$model[x]]]
status_quo <- which.max(base[[1]][t, ])
#get frequency of previous status quo
base_freqs <- base[[1]][, status_quo]/n
#store new status quo
object <- base[[2]]
if(disrupt_params$moves[x] == 2){
new_status_quo <- c(1:disrupt_params$moves[x])[-status_quo]
} else{
new_status_quo <- sample(c(1:disrupt_params$moves[x])[-status_quo], 1)
}
#create table of fresh agents
pop_size <- n*disrupt_params$props[x]
agents <- data.table::data.table(pref = NA,
status_quo = new_status_quo,
advertisement = 0,
negotiation = 0,
payoffs = lapply(1:pop_size, function(x){payoff_matrix_constructor(n_moves = disrupt_params$moves[x], out_of = 1)}),
power = rnorm(pop_size, mean = 0, sd = 1),
outcome = NA,
a_status_quo = lapply(1:pop_size, function(x){c(0, rep(0, disrupt_params$moves[x] - 1))}),
a_advertisement = lapply(1:pop_size, function(x){c(0, 0)}),
a_negotiation = lapply(1:pop_size, function(x){c(0, 0)}),
n_status_quo = lapply(1:pop_size, function(x){rep(1, disrupt_params$moves[x])}),
n_advertisement = lapply(1:pop_size, function(x){c(1, 1)}),
n_negotiation = lapply(1:pop_size, function(x){c(1, 1)}),
cum_status_quo = lapply(1:pop_size, function(x){rep(0, disrupt_params$moves[x])}),
cum_advertisement = lapply(1:pop_size, function(x){c(0, 0)}),
cum_negotiation = lapply(1:pop_size, function(x){c(0, 0)}),
lifetime_payoff = 0)
agents$pref <- sapply(1:pop_size, function(x){which.max(diag(agents$payoffs[[x]]))})
agents <- data.table::data.table(pref = NA,
status_quo = new_status_quo,
advertisement = 0,
negotiation = 0,
payoffs = lapply(1:pop_size, function(x){payoff_matrix_constructor(n_moves = disrupt_params$moves[x], out_of = 1)}),
power = rnorm(pop_size, mean = 0, sd = 1),
outcome = NA,
a_status_quo = lapply(1:pop_size, function(x){c(0, rep(0, disrupt_params$moves[x] - 1))}),
a_advertisement = lapply(1:pop_size, function(x){c(0, 0)}),
a_negotiation = lapply(1:pop_size, function(x){c(0, 0)}),
n_status_quo = lapply(1:pop_size, function(x){rep(1, disrupt_params$moves[x])}),
n_advertisement = lapply(1:pop_size, function(x){c(1, 1)}),
n_negotiation = lapply(1:pop_size, function(x){c(1, 1)}),
cum_status_quo = lapply(1:pop_size, function(x){rep(0, disrupt_params$moves[x])}),
cum_advertisement = lapply(1:pop_size, function(x){c(0, 0)}),
cum_negotiation = lapply(1:pop_size, function(x){c(0, 0)}),
lifetime_payoff = 0)
disrupt_params$moves[x]
payoff_matrix_constructor(n_moves = disrupt_params$moves[x], out_of = 1)
lapply(1:pop_size, function(x){payoff_matrix_constructor(n_moves = disrupt_params$moves[x], out_of = 1)})
base <- base_model[[disrupt_params$model[x]]]
status_quo <- which.max(base[[1]][t, ])
#get frequency of previous status quo
base_freqs <- base[[1]][, status_quo]/n
#store new status quo
object <- base[[2]]
if(disrupt_params$moves[x] == 2){
new_status_quo <- c(1:disrupt_params$moves[x])[-status_quo]
} else{
new_status_quo <- sample(c(1:disrupt_params$moves[x])[-status_quo], 1)
}
#create table of fresh agents
pop_size <- n*disrupt_params$props[x]
agents <- data.table::data.table(pref = NA,
status_quo = new_status_quo,
advertisement = 0,
negotiation = 0,
payoffs = lapply(1:pop_size, function(y){payoff_matrix_constructor(n_moves = disrupt_params$moves[x], out_of = 1)}),
power = rnorm(pop_size, mean = 0, sd = 1),
outcome = NA,
a_status_quo = lapply(1:pop_size, function(y){c(0, rep(0, disrupt_params$moves[x] - 1))}),
a_advertisement = lapply(1:pop_size, function(y){c(0, 0)}),
a_negotiation = lapply(1:pop_size, function(y){c(0, 0)}),
n_status_quo = lapply(1:pop_size, function(y){rep(1, disrupt_params$moves[x])}),
n_advertisement = lapply(1:pop_size, function(y){c(1, 1)}),
n_negotiation = lapply(1:pop_size, function(y){c(1, 1)}),
cum_status_quo = lapply(1:pop_size, function(y){rep(0, disrupt_params$moves[x])}),
cum_advertisement = lapply(1:pop_size, function(y){c(0, 0)}),
cum_negotiation = lapply(1:pop_size, function(y){c(0, 0)}),
lifetime_payoff = 0)
agents$pref <- sapply(1:pop_size, function(y){which.max(diag(agents$payoffs[[y]]))})
agentw
agents
#run disrupt model code
disrupt_model <- parallel::mclapply(1:nrow(disrupt_params), function(x){
#store base model and compute status quo
base <- base_model[[disrupt_params$model[x]]]
status_quo <- which.max(base[[1]][t, ])
#get frequency of previous status quo
base_freqs <- base[[1]][, status_quo]/n
#store new status quo
object <- base[[2]]
if(disrupt_params$moves[x] == 2){
new_status_quo <- c(1:disrupt_params$moves[x])[-status_quo]
} else{
new_status_quo <- sample(c(1:disrupt_params$moves[x])[-status_quo], 1)
}
#create table of fresh agents
pop_size <- n*disrupt_params$props[x]
agents <- data.table::data.table(pref = NA,
status_quo = new_status_quo,
advertisement = 0,
negotiation = 0,
payoffs = lapply(1:pop_size, function(y){payoff_matrix_constructor(n_moves = disrupt_params$moves[x], out_of = 1)}),
power = rnorm(pop_size, mean = 0, sd = 1),
outcome = NA,
a_status_quo = lapply(1:pop_size, function(y){c(0, rep(0, disrupt_params$moves[x] - 1))}),
a_advertisement = lapply(1:pop_size, function(y){c(0, 0)}),
a_negotiation = lapply(1:pop_size, function(y){c(0, 0)}),
n_status_quo = lapply(1:pop_size, function(y){rep(1, disrupt_params$moves[x])}),
n_advertisement = lapply(1:pop_size, function(y){c(1, 1)}),
n_negotiation = lapply(1:pop_size, function(y){c(1, 1)}),
cum_status_quo = lapply(1:pop_size, function(y){rep(0, disrupt_params$moves[x])}),
cum_advertisement = lapply(1:pop_size, function(y){c(0, 0)}),
cum_negotiation = lapply(1:pop_size, function(y){c(0, 0)}),
lifetime_payoff = 0)
agents$pref <- sapply(1:pop_size, function(y){which.max(diag(agents$payoffs[[y]]))})
#overwrite proportion of existing agents with new agents
object <- rbind(object[1:(n-pop_size), ], agents)
#run new simulations and store simplified output
output <- model(pop_size = n, t = t_2, neg_cost = disrupt_params$cost[x], n_moves = disrupt_params$moves[x], supply_agents = object, gamma = disrupt_params$gamma[x], f = disrupt_params$f[x], networked = disrupt_params$networked[x])
c(base_freqs, sapply(1:t_2, function(y){length(which(output[[y]]$status_quo == status_quo))/n}))
}, mc.cores = parallel::detectCores() - 1)
